{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1 ЗАДАНИЕ"
      ],
      "metadata": {
        "id": "-w9kI70uT6ad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Загрузка данных\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Нормализация данных\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Преобразование меток в one-hot encoding\n",
        "y_train_categorical = keras.utils.to_categorical(y_train, 10)\n",
        "y_test_categorical = keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Базовая модель\n",
        "def create_base_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Модель с измененной архитектурой (добавлен слой, изменен размер фильтра)\n",
        "def create_modified_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Conv2D(32, (5, 5), activation='relu', input_shape=(32, 32, 3)),  # Изменен размер фильтра\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(64, (5, 5), activation='relu'),  # Изменен размер фильтра\n",
        "        keras.layers.MaxPooling2D((2, 2)),\n",
        "        keras.layers.Conv2D(128, (3, 3), activation='relu'),  # Добавлен новый слой\n",
        "        keras.layers.Flatten(),\n",
        "        keras.layers.Dense(128, activation='relu'),\n",
        "        keras.layers.Dropout(0.5),\n",
        "        keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Обучение и оценка моделей\n",
        "def train_and_evaluate(model, model_name):\n",
        "    print(f\"\\n=== Обучение {model_name} ===\")\n",
        "    model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "    history = model.fit(x_train, y_train_categorical,\n",
        "                       epochs=10,\n",
        "                       batch_size=64,\n",
        "                       validation_data=(x_test, y_test_categorical),\n",
        "                       verbose=1)\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(x_test, y_test_categorical, verbose=0)\n",
        "    print(f\"{model_name} - Точность на тесте: {test_acc:.4f}\")\n",
        "\n",
        "    return history, test_acc\n",
        "\n",
        "# Сравнение моделей\n",
        "base_model = create_base_model()\n",
        "modified_model = create_modified_model()\n",
        "\n",
        "base_history, base_acc = train_and_evaluate(base_model, \"Базовая модель\")\n",
        "modified_history, modified_acc = train_and_evaluate(modified_model, \"Модифицированная модель\")\n",
        "\n",
        "print(f\"\\n=== СРАВНЕНИЕ РЕЗУЛЬТАТОВ ===\")\n",
        "print(f\"Базовая модель точность: {base_acc:.4f}\")\n",
        "print(f\"Модифицированная модель точность: {modified_acc:.4f}\")\n",
        "print(f\"Разница: {modified_acc - base_acc:.4f}\")"
      ],
      "metadata": {
        "id": "g4__evkGQDxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 ЗАДАНИЕ"
      ],
      "metadata": {
        "id": "9IPftrsjUCTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_optimizers_and_epochs():\n",
        "    optimizers = {\n",
        "        'adam': keras.optimizers.Adam(learning_rate=0.001),\n",
        "        'sgd': keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "        'rmsprop': keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "    }\n",
        "\n",
        "    epochs_list = [10, 20]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for opt_name, optimizer in optimizers.items():\n",
        "        for epochs in epochs_list:\n",
        "            print(f\"\\n=== {opt_name.upper()} - {epochs} эпох ===\")\n",
        "\n",
        "            model = create_base_model()\n",
        "            model.compile(optimizer=optimizer,\n",
        "                         loss='categorical_crossentropy',\n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "            history = model.fit(x_train, y_train_categorical,\n",
        "                              epochs=epochs,\n",
        "                              batch_size=64,\n",
        "                              validation_data=(x_test, y_test_categorical),\n",
        "                              verbose=0)\n",
        "\n",
        "            test_loss, test_acc = model.evaluate(x_test, y_test_categorical, verbose=0)\n",
        "            results[f\"{opt_name}_{epochs}epochs\"] = {\n",
        "                'accuracy': test_acc,\n",
        "                'history': history\n",
        "            }\n",
        "\n",
        "            print(f\"Точность: {test_acc:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Запуск сравнения\n",
        "results = compare_optimizers_and_epochs()\n",
        "\n",
        "# Визуализация результатов\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# График точности\n",
        "plt.subplot(1, 2, 1)\n",
        "for key, result in results.items():\n",
        "    plt.plot(result['history'].history['val_accuracy'], label=key)\n",
        "plt.title('Точность на валидации')\n",
        "plt.xlabel('Эпохи')\n",
        "plt.ylabel('Точность')\n",
        "plt.legend()\n",
        "\n",
        "# График потерь\n",
        "plt.subplot(1, 2, 2)\n",
        "for key, result in results.items():\n",
        "    plt.plot(result['history'].history['val_loss'], label=key)\n",
        "plt.title('Потери на валидации')\n",
        "plt.xlabel('Эпохи')\n",
        "plt.ylabel('Потери')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Анализ результатов\n",
        "print(\"\\n=== АНАЛИЗ РЕЗУЛЬТАТОВ ===\")\n",
        "for key, result in results.items():\n",
        "    print(f\"{key}: {result['accuracy']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN6K9V8OQEcz",
        "outputId": "dbf1b096-e030-46a7-bced-f5a20969942c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ADAM - 10 эпох ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 ЗАДАНИЕ"
      ],
      "metadata": {
        "id": "qduDXwu5UFS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_errors_and_confusion_matrix(model, x_test, y_test):\n",
        "    # Предсказания модели\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = y_test.flatten()\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "    # Визуализация Confusion Matrix\n",
        "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Предсказанные классы')\n",
        "    plt.ylabel('Истинные классы')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Анализ наиболее часто путающихся классов\n",
        "    print(\"\\n=== АНАЛИЗ ОШИБОК ===\")\n",
        "\n",
        "    # Нормированная confusion matrix для анализа процентов\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    # Находим пары классов, которые чаще всего путаются\n",
        "    confusion_pairs = []\n",
        "    for i in range(len(class_names)):\n",
        "        for j in range(len(class_names)):\n",
        "            if i != j and cm[i, j] > 0:\n",
        "                confusion_pairs.append((i, j, cm[i, j], cm_normalized[i, j]))\n",
        "\n",
        "    # Сортируем по количеству ошибок\n",
        "    confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "    print(\"Наиболее часто путающиеся классы:\")\n",
        "    for i, j, count, percentage in confusion_pairs[:10]:\n",
        "        print(f\"{class_names[i]} -> {class_names[j]}: {count} ошибок ({percentage:.2%})\")\n",
        "\n",
        "    # Визуализация примеров ошибок\n",
        "    visualize_error_examples(model, x_test, y_true_classes, class_names)\n",
        "\n",
        "def visualize_error_examples(model, x_test, y_true, class_names):\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Находим индексы ошибок\n",
        "    errors = np.where(y_pred_classes != y_true)[0]\n",
        "\n",
        "    # Выбираем случайные примеры ошибок\n",
        "    np.random.shuffle(errors)\n",
        "    error_indices = errors[:12]\n",
        "\n",
        "    # Визуализация\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, idx in enumerate(error_indices):\n",
        "        plt.subplot(3, 4, i + 1)\n",
        "        plt.imshow(x_test[idx])\n",
        "        plt.title(f'Истинный: {class_names[y_true[idx]]}\\nПредсказанный: {class_names[y_pred_classes[idx]]}')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Используем лучшую модель для анализа ошибок\n",
        "best_model = create_base_model()\n",
        "best_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "best_model.fit(x_train, y_train_categorical, epochs=10, batch_size=64, verbose=0)\n",
        "\n",
        "# Анализ ошибок\n",
        "analyze_errors_and_confusion_matrix(best_model, x_test, y_test)"
      ],
      "metadata": {
        "id": "BE-waSS-QESF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Добро пожаловать в Colab!",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}